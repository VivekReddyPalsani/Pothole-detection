{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, patch_size=(800, 800), overlap=100):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['image_path'].unique())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data['image_path'].unique()[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        rows = self.data[self.data['image_path'] == img_path]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for _, row in rows.iterrows():\n",
    "            x, y, w, h = row['x'], row['y'], row['w'], row['h']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(1)\n",
    "\n",
    "        patches, patch_boxes, patch_labels = self.create_patches(image, boxes, labels)\n",
    "\n",
    "        return patches, patch_boxes, patch_labels\n",
    "\n",
    "    def create_patches(self, image, boxes, labels):\n",
    "        patches = []\n",
    "        patch_boxes = []\n",
    "        patch_labels = []\n",
    "        width, height = image.size\n",
    "        pw, ph = self.patch_size\n",
    "\n",
    "        for y_offset in range(0, height, ph - self.overlap):\n",
    "            for x_offset in range(0, width, pw - self.overlap):\n",
    "                patch_width = min(pw, width - x_offset)\n",
    "                patch_height = min(ph, height - y_offset)\n",
    "                \n",
    "                patch = image.crop((x_offset, y_offset, x_offset + patch_width, y_offset + patch_height))\n",
    "                \n",
    "                patch_bboxes = []\n",
    "                patch_labels_local = []\n",
    "                for box, label in zip(boxes, labels):\n",
    "                    x_min, y_min, x_max, y_max = box\n",
    "                    if (x_min >= x_offset and x_max <= x_offset + patch_width) and (y_min >= y_offset and y_max <= y_offset + patch_height):\n",
    "                        adjusted_box = [\n",
    "                            x_min - x_offset,\n",
    "                            y_min - y_offset,\n",
    "                            x_max - x_offset,\n",
    "                            y_max - y_offset\n",
    "                        ]\n",
    "                        \n",
    "                        if adjusted_box[2] > adjusted_box[0] and adjusted_box[3] > adjusted_box[1]:\n",
    "                            patch_bboxes.append(adjusted_box)\n",
    "                            patch_labels_local.append(label)\n",
    "\n",
    "                if len(patch_bboxes) == 0:\n",
    "                    patch_labels_local = [0]  \n",
    "                \n",
    "                if self.transform:\n",
    "                    patch = self.transform(patch)\n",
    "                patches.append(patch)\n",
    "                patch_boxes.append(torch.tensor(patch_bboxes, dtype=torch.float32))\n",
    "                patch_labels.append(torch.tensor(patch_labels_local, dtype=torch.int64))\n",
    "\n",
    "        return patches, patch_boxes, patch_labels\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"/Users/vivekreddypalsani/Documents/mahindra/mahindra-3rd/3rd-fall/DIP/project/Dataset/train/Train_data/Cropped_data/csv/combined_samples.csv\"  # Replace with your CSV file path\n",
    "dataset = PotholeDataset(csv_file=csv_file_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2 \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "model.train()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for patches, patch_boxes, patch_labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for patch, boxes, labels in zip(patches[0], patch_boxes[0], patch_labels[0]):\n",
    "            patch = patch.to(device)\n",
    "            boxes = boxes.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "            if len(boxes) == 0: \n",
    "                target = {\"boxes\": torch.empty((0, 4), dtype=torch.float32).to(device),\n",
    "                          \"labels\": torch.empty((0,), dtype=torch.int64).to(device)}\n",
    "\n",
    "            loss_dict = model([patch], [target])\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            epoch_loss += losses.item()\n",
    "\n",
    "            losses.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
